[data paths]
path_local =  ./DATA_datasets_training_testing/
train_imgs_original = DATA_dataset_imgs_train.hdf5
train_groundTruth = DATA_dataset_groundTruth_train.hdf5
train_border_masks = DATA_dataset_borderMasks_train.hdf5
train_watersheds = DATA_dataset_watersheds_train.hdf5
test_imgs_original = DATA_dataset_imgs_test.hdf5
test_groundTruth = DATA_dataset_groundTruth_test.hdf5
test_border_masks = DATA_dataset_borderMasks_test.hdf5
test_watersheds = DATA_dataset_watersheds_test.hdf5



[experiment name]
name = arch2_batch_adam_r02


[data attributes]
#Dimensions of the patches extracted from the full images
patch_height= 128
patch_width = 128


[training settings]
#number of total patches:
N_subimgs = 6000
#if patches are extracted only inside the field of view:
inside_FOV = True
#Number of training epochs
N_epochs = 100
batch_size = 64
#if running with nohup
nohup = True


[testing settings]
#Choose the model to test: best==epoch with min loss, last==last epoch
best_last = best
#number of full images for the test (max 20)
full_images_to_test = 20
#How many original-groundTruth-prediction images are visualized in each image
N_group_visual = 1
#Compute average in the prediction, improve results but require more patches to be predicted
average_mode = True
#Only if average_mode==True. Stride for patch extraction, lower value require more patches to be predicted
stride_height = 5
stride_width = 5
#if running with nohup
nohup = False


[notes]
# optimizer=sgd
# dropout used
# categorical cross entropy 
# standard model